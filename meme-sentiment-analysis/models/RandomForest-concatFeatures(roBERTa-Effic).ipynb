{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import class_weight \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import yaml\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../config.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        configs = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED                       = configs['SEED']\n",
    "PATH_TO_TRAIN_DS_PROCESSED = str(configs['ROOT_DIR'] + configs['PATH_TO_TRAIN_DS_PROCESSED'])\n",
    "PATH_TO_EXTRACTED_FEATURES = str(configs['ROOT_DIR'] + configs['PATH_TO_EXTRACTED_FEATURES'])\n",
    "\n",
    "PATH_TO_MODELS = str(configs['ROOT_DIR'] + configs['PATH_TO_MODELS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5453, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1415.jpeg</td>\n",
       "      <td>if you want to view paradis simpli look around...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_6460.png</td>\n",
       "      <td>if i had a brick for everi lie hillari told i ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_2303.png</td>\n",
       "      <td>that thing over there can i eat that</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_2417.png</td>\n",
       "      <td>my dad point to liam and said when did david b...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_11.jpg</td>\n",
       "      <td>probabl the first man to do year challeng chen...</td>\n",
       "      <td>funny</td>\n",
       "      <td>general</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name                                               text  \\\n",
       "0  image_1415.jpeg  if you want to view paradis simpli look around...   \n",
       "1   image_6460.png  if i had a brick for everi lie hillari told i ...   \n",
       "2   image_2303.png               that thing over there can i eat that   \n",
       "3   image_2417.png  my dad point to liam and said when did david b...   \n",
       "4     image_11.jpg  probabl the first man to do year challeng chen...   \n",
       "\n",
       "       humour        sarcasm       offensive  motivational         target  \n",
       "0   not_funny  not_sarcastic   not_offensive  motivational       positive  \n",
       "1   hilarious        general  very_offensive  motivational       positive  \n",
       "2  very_funny        general   not_offensive  motivational  very_positive  \n",
       "3   not_funny        general  very_offensive  motivational        neutral  \n",
       "4       funny        general  very_offensive  motivational       negative  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base           = pd.read_csv(PATH_TO_TRAIN_DS_PROCESSED)\n",
    "\n",
    "effic_features = pd.read_csv(PATH_TO_EXTRACTED_FEATURES + \"EfficientNet-train.csv\")\n",
    "effic_features.drop(effic_features.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "\n",
    "roberta_features  = pd.read_csv(PATH_TO_EXTRACTED_FEATURES + \"roberta-base-train.csv\")\n",
    "roberta_features  = roberta_features.iloc[1: , :] #desconsiderando a primeira linha porque só contém zeros! Os zeros foram adicionados para evitar erros na adição de novas linhas no numpy.array em BERT-featureExtractor.ipynb\n",
    "roberta_features.drop(roberta_features.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "\n",
    "print(base.shape)\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5453, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.622064</td>\n",
       "      <td>0.331342</td>\n",
       "      <td>0.625570</td>\n",
       "      <td>-1.188456</td>\n",
       "      <td>0.890898</td>\n",
       "      <td>-0.297572</td>\n",
       "      <td>-0.087452</td>\n",
       "      <td>0.664493</td>\n",
       "      <td>-0.408972</td>\n",
       "      <td>-1.156423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415184</td>\n",
       "      <td>0.317160</td>\n",
       "      <td>-0.131766</td>\n",
       "      <td>-0.559810</td>\n",
       "      <td>-0.383801</td>\n",
       "      <td>0.351369</td>\n",
       "      <td>0.110016</td>\n",
       "      <td>0.449329</td>\n",
       "      <td>-0.786426</td>\n",
       "      <td>0.073209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.604108</td>\n",
       "      <td>0.337911</td>\n",
       "      <td>0.950010</td>\n",
       "      <td>-1.028117</td>\n",
       "      <td>0.515339</td>\n",
       "      <td>-0.150530</td>\n",
       "      <td>-0.114648</td>\n",
       "      <td>0.725604</td>\n",
       "      <td>-0.092860</td>\n",
       "      <td>-0.932656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326043</td>\n",
       "      <td>0.296483</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>-0.558398</td>\n",
       "      <td>-0.228380</td>\n",
       "      <td>0.049417</td>\n",
       "      <td>0.472585</td>\n",
       "      <td>0.474540</td>\n",
       "      <td>-0.799658</td>\n",
       "      <td>0.027630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.757757</td>\n",
       "      <td>0.254757</td>\n",
       "      <td>0.857170</td>\n",
       "      <td>-1.022734</td>\n",
       "      <td>0.183830</td>\n",
       "      <td>-0.053854</td>\n",
       "      <td>-0.020377</td>\n",
       "      <td>0.528923</td>\n",
       "      <td>-0.085957</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181596</td>\n",
       "      <td>0.280393</td>\n",
       "      <td>0.112610</td>\n",
       "      <td>-0.526918</td>\n",
       "      <td>-0.338471</td>\n",
       "      <td>0.271118</td>\n",
       "      <td>0.433552</td>\n",
       "      <td>0.559687</td>\n",
       "      <td>-0.774118</td>\n",
       "      <td>-0.074605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.657207</td>\n",
       "      <td>0.574977</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>-1.314496</td>\n",
       "      <td>0.885670</td>\n",
       "      <td>-0.533778</td>\n",
       "      <td>0.133388</td>\n",
       "      <td>0.776399</td>\n",
       "      <td>-0.804361</td>\n",
       "      <td>-1.487674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251450</td>\n",
       "      <td>0.408799</td>\n",
       "      <td>-0.164519</td>\n",
       "      <td>-0.577932</td>\n",
       "      <td>-0.502540</td>\n",
       "      <td>0.127542</td>\n",
       "      <td>0.434763</td>\n",
       "      <td>0.481590</td>\n",
       "      <td>-0.771126</td>\n",
       "      <td>-0.040969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.568037</td>\n",
       "      <td>0.568159</td>\n",
       "      <td>0.926396</td>\n",
       "      <td>-1.076364</td>\n",
       "      <td>0.988210</td>\n",
       "      <td>-0.487285</td>\n",
       "      <td>-0.020380</td>\n",
       "      <td>0.934860</td>\n",
       "      <td>-0.764776</td>\n",
       "      <td>-1.474329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428683</td>\n",
       "      <td>0.364758</td>\n",
       "      <td>-0.088232</td>\n",
       "      <td>-0.751990</td>\n",
       "      <td>-0.595538</td>\n",
       "      <td>0.215889</td>\n",
       "      <td>0.454045</td>\n",
       "      <td>0.441468</td>\n",
       "      <td>-0.694934</td>\n",
       "      <td>-0.241814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "1 -0.622064  0.331342  0.625570 -1.188456  0.890898 -0.297572 -0.087452   \n",
       "2 -0.604108  0.337911  0.950010 -1.028117  0.515339 -0.150530 -0.114648   \n",
       "3 -0.757757  0.254757  0.857170 -1.022734  0.183830 -0.053854 -0.020377   \n",
       "4 -0.657207  0.574977  0.775252 -1.314496  0.885670 -0.533778  0.133388   \n",
       "5 -0.568037  0.568159  0.926396 -1.076364  0.988210 -0.487285 -0.020380   \n",
       "\n",
       "          7         8         9  ...       758       759       760       761  \\\n",
       "1  0.664493 -0.408972 -1.156423  ...  0.415184  0.317160 -0.131766 -0.559810   \n",
       "2  0.725604 -0.092860 -0.932656  ...  0.326043  0.296483  0.067706 -0.558398   \n",
       "3  0.528923 -0.085957 -0.559990  ...  0.181596  0.280393  0.112610 -0.526918   \n",
       "4  0.776399 -0.804361 -1.487674  ...  0.251450  0.408799 -0.164519 -0.577932   \n",
       "5  0.934860 -0.764776 -1.474329  ...  0.428683  0.364758 -0.088232 -0.751990   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "1 -0.383801  0.351369  0.110016  0.449329 -0.786426  0.073209  \n",
       "2 -0.228380  0.049417  0.472585  0.474540 -0.799658  0.027630  \n",
       "3 -0.338471  0.271118  0.433552  0.559687 -0.774118 -0.074605  \n",
       "4 -0.502540  0.127542  0.434763  0.481590 -0.771126 -0.040969  \n",
       "5 -0.595538  0.215889  0.454045  0.441468 -0.694934 -0.241814  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(roberta_features.shape)\n",
    "roberta_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5453, 1280)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.042384</td>\n",
       "      <td>-0.061363</td>\n",
       "      <td>-0.100872</td>\n",
       "      <td>0.032875</td>\n",
       "      <td>-0.022561</td>\n",
       "      <td>-0.002880</td>\n",
       "      <td>-0.092080</td>\n",
       "      <td>0.154064</td>\n",
       "      <td>0.289251</td>\n",
       "      <td>-0.147277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172624</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.363466</td>\n",
       "      <td>0.393509</td>\n",
       "      <td>-0.039090</td>\n",
       "      <td>-0.089707</td>\n",
       "      <td>-0.078176</td>\n",
       "      <td>-0.053020</td>\n",
       "      <td>0.416281</td>\n",
       "      <td>-0.102968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.067793</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>0.318771</td>\n",
       "      <td>-0.042084</td>\n",
       "      <td>0.158128</td>\n",
       "      <td>-0.096783</td>\n",
       "      <td>-0.078802</td>\n",
       "      <td>-0.065242</td>\n",
       "      <td>-0.137934</td>\n",
       "      <td>-0.122118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003128</td>\n",
       "      <td>0.215171</td>\n",
       "      <td>0.081113</td>\n",
       "      <td>-0.046309</td>\n",
       "      <td>-0.018203</td>\n",
       "      <td>0.114962</td>\n",
       "      <td>-0.047569</td>\n",
       "      <td>-0.135591</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>0.074974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.944058</td>\n",
       "      <td>-0.076654</td>\n",
       "      <td>-0.066291</td>\n",
       "      <td>-0.080416</td>\n",
       "      <td>0.814247</td>\n",
       "      <td>-0.065318</td>\n",
       "      <td>-0.112185</td>\n",
       "      <td>2.324079</td>\n",
       "      <td>-0.094965</td>\n",
       "      <td>-0.092683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721857</td>\n",
       "      <td>-0.149343</td>\n",
       "      <td>0.161383</td>\n",
       "      <td>-0.014381</td>\n",
       "      <td>-0.052333</td>\n",
       "      <td>2.049798</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>0.314507</td>\n",
       "      <td>-0.085552</td>\n",
       "      <td>0.049666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.228229</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>-0.095749</td>\n",
       "      <td>-0.094697</td>\n",
       "      <td>-0.164453</td>\n",
       "      <td>-0.134290</td>\n",
       "      <td>-0.027651</td>\n",
       "      <td>0.295090</td>\n",
       "      <td>-0.090984</td>\n",
       "      <td>-0.110664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426313</td>\n",
       "      <td>0.282934</td>\n",
       "      <td>-0.037594</td>\n",
       "      <td>1.015053</td>\n",
       "      <td>-0.130066</td>\n",
       "      <td>-0.121831</td>\n",
       "      <td>-0.043130</td>\n",
       "      <td>-0.174937</td>\n",
       "      <td>-0.081547</td>\n",
       "      <td>-0.028557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.056007</td>\n",
       "      <td>0.172222</td>\n",
       "      <td>0.286570</td>\n",
       "      <td>-0.086260</td>\n",
       "      <td>0.061207</td>\n",
       "      <td>-0.104899</td>\n",
       "      <td>-0.021336</td>\n",
       "      <td>0.992542</td>\n",
       "      <td>-0.032700</td>\n",
       "      <td>-0.037638</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065959</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.529718</td>\n",
       "      <td>-0.035574</td>\n",
       "      <td>-0.118270</td>\n",
       "      <td>0.464599</td>\n",
       "      <td>0.113052</td>\n",
       "      <td>0.444527</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>-0.039775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.042384 -0.061363 -0.100872  0.032875 -0.022561 -0.002880 -0.092080   \n",
       "1 -0.067793 -0.049741  0.318771 -0.042084  0.158128 -0.096783 -0.078802   \n",
       "2  0.944058 -0.076654 -0.066291 -0.080416  0.814247 -0.065318 -0.112185   \n",
       "3  0.228229  0.018523 -0.095749 -0.094697 -0.164453 -0.134290 -0.027651   \n",
       "4 -0.056007  0.172222  0.286570 -0.086260  0.061207 -0.104899 -0.021336   \n",
       "\n",
       "          7         8         9  ...      1270      1271      1272      1273  \\\n",
       "0  0.154064  0.289251 -0.147277  ...  0.172624  0.052139  0.363466  0.393509   \n",
       "1 -0.065242 -0.137934 -0.122118  ... -0.003128  0.215171  0.081113 -0.046309   \n",
       "2  2.324079 -0.094965 -0.092683  ...  0.721857 -0.149343  0.161383 -0.014381   \n",
       "3  0.295090 -0.090984 -0.110664  ...  0.426313  0.282934 -0.037594  1.015053   \n",
       "4  0.992542 -0.032700 -0.037638  ...  1.065959 -0.000900  0.529718 -0.035574   \n",
       "\n",
       "       1274      1275      1276      1277      1278      1279  \n",
       "0 -0.039090 -0.089707 -0.078176 -0.053020  0.416281 -0.102968  \n",
       "1 -0.018203  0.114962 -0.047569 -0.135591 -0.045568  0.074974  \n",
       "2 -0.052333  2.049798  0.108311  0.314507 -0.085552  0.049666  \n",
       "3 -0.130066 -0.121831 -0.043130 -0.174937 -0.081547 -0.028557  \n",
       "4 -0.118270  0.464599  0.113052  0.444527  0.016761 -0.039775  \n",
       "\n",
       "[5 rows x 1280 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(effic_features.shape)\n",
    "effic_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenando os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5453, 2049)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.622064</td>\n",
       "      <td>0.331342</td>\n",
       "      <td>0.625570</td>\n",
       "      <td>-1.188456</td>\n",
       "      <td>0.890898</td>\n",
       "      <td>-0.297572</td>\n",
       "      <td>-0.087452</td>\n",
       "      <td>0.664493</td>\n",
       "      <td>-0.408972</td>\n",
       "      <td>-1.156423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.363466</td>\n",
       "      <td>0.393509</td>\n",
       "      <td>-0.039090</td>\n",
       "      <td>-0.089707</td>\n",
       "      <td>-0.078176</td>\n",
       "      <td>-0.053020</td>\n",
       "      <td>0.416281</td>\n",
       "      <td>-0.102968</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.604108</td>\n",
       "      <td>0.337911</td>\n",
       "      <td>0.950010</td>\n",
       "      <td>-1.028117</td>\n",
       "      <td>0.515339</td>\n",
       "      <td>-0.150530</td>\n",
       "      <td>-0.114648</td>\n",
       "      <td>0.725604</td>\n",
       "      <td>-0.092860</td>\n",
       "      <td>-0.932656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215171</td>\n",
       "      <td>0.081113</td>\n",
       "      <td>-0.046309</td>\n",
       "      <td>-0.018203</td>\n",
       "      <td>0.114962</td>\n",
       "      <td>-0.047569</td>\n",
       "      <td>-0.135591</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>0.074974</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.757757</td>\n",
       "      <td>0.254757</td>\n",
       "      <td>0.857170</td>\n",
       "      <td>-1.022734</td>\n",
       "      <td>0.183830</td>\n",
       "      <td>-0.053854</td>\n",
       "      <td>-0.020377</td>\n",
       "      <td>0.528923</td>\n",
       "      <td>-0.085957</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149343</td>\n",
       "      <td>0.161383</td>\n",
       "      <td>-0.014381</td>\n",
       "      <td>-0.052333</td>\n",
       "      <td>2.049798</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>0.314507</td>\n",
       "      <td>-0.085552</td>\n",
       "      <td>0.049666</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.657207</td>\n",
       "      <td>0.574977</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>-1.314496</td>\n",
       "      <td>0.885670</td>\n",
       "      <td>-0.533778</td>\n",
       "      <td>0.133388</td>\n",
       "      <td>0.776399</td>\n",
       "      <td>-0.804361</td>\n",
       "      <td>-1.487674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282934</td>\n",
       "      <td>-0.037594</td>\n",
       "      <td>1.015053</td>\n",
       "      <td>-0.130066</td>\n",
       "      <td>-0.121831</td>\n",
       "      <td>-0.043130</td>\n",
       "      <td>-0.174937</td>\n",
       "      <td>-0.081547</td>\n",
       "      <td>-0.028557</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.568037</td>\n",
       "      <td>0.568159</td>\n",
       "      <td>0.926396</td>\n",
       "      <td>-1.076364</td>\n",
       "      <td>0.988210</td>\n",
       "      <td>-0.487285</td>\n",
       "      <td>-0.020380</td>\n",
       "      <td>0.934860</td>\n",
       "      <td>-0.764776</td>\n",
       "      <td>-1.474329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.529718</td>\n",
       "      <td>-0.035574</td>\n",
       "      <td>-0.118270</td>\n",
       "      <td>0.464599</td>\n",
       "      <td>0.113052</td>\n",
       "      <td>0.444527</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>-0.039775</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.622064  0.331342  0.625570 -1.188456  0.890898 -0.297572 -0.087452   \n",
       "1 -0.604108  0.337911  0.950010 -1.028117  0.515339 -0.150530 -0.114648   \n",
       "2 -0.757757  0.254757  0.857170 -1.022734  0.183830 -0.053854 -0.020377   \n",
       "3 -0.657207  0.574977  0.775252 -1.314496  0.885670 -0.533778  0.133388   \n",
       "4 -0.568037  0.568159  0.926396 -1.076364  0.988210 -0.487285 -0.020380   \n",
       "\n",
       "          7         8         9  ...      2039      2040      2041      2042  \\\n",
       "0  0.664493 -0.408972 -1.156423  ...  0.052139  0.363466  0.393509 -0.039090   \n",
       "1  0.725604 -0.092860 -0.932656  ...  0.215171  0.081113 -0.046309 -0.018203   \n",
       "2  0.528923 -0.085957 -0.559990  ... -0.149343  0.161383 -0.014381 -0.052333   \n",
       "3  0.776399 -0.804361 -1.487674  ...  0.282934 -0.037594  1.015053 -0.130066   \n",
       "4  0.934860 -0.764776 -1.474329  ... -0.000900  0.529718 -0.035574 -0.118270   \n",
       "\n",
       "       2043      2044      2045      2046      2047         target  \n",
       "0 -0.089707 -0.078176 -0.053020  0.416281 -0.102968       positive  \n",
       "1  0.114962 -0.047569 -0.135591 -0.045568  0.074974       positive  \n",
       "2  2.049798  0.108311  0.314507 -0.085552  0.049666  very_positive  \n",
       "3 -0.121831 -0.043130 -0.174937 -0.081547 -0.028557        neutral  \n",
       "4  0.464599  0.113052  0.444527  0.016761 -0.039775       negative  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_base = pd.DataFrame(np.concatenate((roberta_features, effic_features), axis=1))\n",
    "n_base['target'] = base.target\n",
    "print(n_base.shape)\n",
    "n_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerando somente as labels 'negative', 'neutral' e 'positive'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.622064</td>\n",
       "      <td>0.331342</td>\n",
       "      <td>0.625570</td>\n",
       "      <td>-1.188456</td>\n",
       "      <td>0.890898</td>\n",
       "      <td>-0.297572</td>\n",
       "      <td>-0.087452</td>\n",
       "      <td>0.664493</td>\n",
       "      <td>-0.408972</td>\n",
       "      <td>-1.156423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.363466</td>\n",
       "      <td>0.393509</td>\n",
       "      <td>-0.039090</td>\n",
       "      <td>-0.089707</td>\n",
       "      <td>-0.078176</td>\n",
       "      <td>-0.053020</td>\n",
       "      <td>0.416281</td>\n",
       "      <td>-0.102968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.604108</td>\n",
       "      <td>0.337911</td>\n",
       "      <td>0.950010</td>\n",
       "      <td>-1.028117</td>\n",
       "      <td>0.515339</td>\n",
       "      <td>-0.150530</td>\n",
       "      <td>-0.114648</td>\n",
       "      <td>0.725604</td>\n",
       "      <td>-0.092860</td>\n",
       "      <td>-0.932656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215171</td>\n",
       "      <td>0.081113</td>\n",
       "      <td>-0.046309</td>\n",
       "      <td>-0.018203</td>\n",
       "      <td>0.114962</td>\n",
       "      <td>-0.047569</td>\n",
       "      <td>-0.135591</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>0.074974</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.757757</td>\n",
       "      <td>0.254757</td>\n",
       "      <td>0.857170</td>\n",
       "      <td>-1.022734</td>\n",
       "      <td>0.183830</td>\n",
       "      <td>-0.053854</td>\n",
       "      <td>-0.020377</td>\n",
       "      <td>0.528923</td>\n",
       "      <td>-0.085957</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149343</td>\n",
       "      <td>0.161383</td>\n",
       "      <td>-0.014381</td>\n",
       "      <td>-0.052333</td>\n",
       "      <td>2.049798</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>0.314507</td>\n",
       "      <td>-0.085552</td>\n",
       "      <td>0.049666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.657207</td>\n",
       "      <td>0.574977</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>-1.314496</td>\n",
       "      <td>0.885670</td>\n",
       "      <td>-0.533778</td>\n",
       "      <td>0.133388</td>\n",
       "      <td>0.776399</td>\n",
       "      <td>-0.804361</td>\n",
       "      <td>-1.487674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282934</td>\n",
       "      <td>-0.037594</td>\n",
       "      <td>1.015053</td>\n",
       "      <td>-0.130066</td>\n",
       "      <td>-0.121831</td>\n",
       "      <td>-0.043130</td>\n",
       "      <td>-0.174937</td>\n",
       "      <td>-0.081547</td>\n",
       "      <td>-0.028557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.568037</td>\n",
       "      <td>0.568159</td>\n",
       "      <td>0.926396</td>\n",
       "      <td>-1.076364</td>\n",
       "      <td>0.988210</td>\n",
       "      <td>-0.487285</td>\n",
       "      <td>-0.020380</td>\n",
       "      <td>0.934860</td>\n",
       "      <td>-0.764776</td>\n",
       "      <td>-1.474329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.529718</td>\n",
       "      <td>-0.035574</td>\n",
       "      <td>-0.118270</td>\n",
       "      <td>0.464599</td>\n",
       "      <td>0.113052</td>\n",
       "      <td>0.444527</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>-0.039775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.622064  0.331342  0.625570 -1.188456  0.890898 -0.297572 -0.087452   \n",
       "1 -0.604108  0.337911  0.950010 -1.028117  0.515339 -0.150530 -0.114648   \n",
       "2 -0.757757  0.254757  0.857170 -1.022734  0.183830 -0.053854 -0.020377   \n",
       "3 -0.657207  0.574977  0.775252 -1.314496  0.885670 -0.533778  0.133388   \n",
       "4 -0.568037  0.568159  0.926396 -1.076364  0.988210 -0.487285 -0.020380   \n",
       "\n",
       "          7         8         9  ...      2039      2040      2041      2042  \\\n",
       "0  0.664493 -0.408972 -1.156423  ...  0.052139  0.363466  0.393509 -0.039090   \n",
       "1  0.725604 -0.092860 -0.932656  ...  0.215171  0.081113 -0.046309 -0.018203   \n",
       "2  0.528923 -0.085957 -0.559990  ... -0.149343  0.161383 -0.014381 -0.052333   \n",
       "3  0.776399 -0.804361 -1.487674  ...  0.282934 -0.037594  1.015053 -0.130066   \n",
       "4  0.934860 -0.764776 -1.474329  ... -0.000900  0.529718 -0.035574 -0.118270   \n",
       "\n",
       "       2043      2044      2045      2046      2047  target  \n",
       "0 -0.089707 -0.078176 -0.053020  0.416281 -0.102968       2  \n",
       "1  0.114962 -0.047569 -0.135591 -0.045568  0.074974       2  \n",
       "2  2.049798  0.108311  0.314507 -0.085552  0.049666       2  \n",
       "3 -0.121831 -0.043130 -0.174937 -0.081547 -0.028557       1  \n",
       "4  0.464599  0.113052  0.444527  0.016761 -0.039775       0  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_base.target.replace(\"very_positive\", \n",
    "           \"positive\", \n",
    "           inplace=True)\n",
    "n_base.target.replace(\"very_negative\", \n",
    "           \"negative\", \n",
    "           inplace=True)    \n",
    "NUM_LABELS = len(n_base.target.unique())\n",
    "n_base.target = n_base.target.astype('category').cat.codes\n",
    "n_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separação do treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4362, 2049) (1091, 2049)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>-0.618610</td>\n",
       "      <td>0.463183</td>\n",
       "      <td>0.744717</td>\n",
       "      <td>-1.020731</td>\n",
       "      <td>0.811868</td>\n",
       "      <td>-0.058083</td>\n",
       "      <td>-0.183214</td>\n",
       "      <td>0.905942</td>\n",
       "      <td>-0.576029</td>\n",
       "      <td>-1.222059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028469</td>\n",
       "      <td>-0.040667</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>-0.114967</td>\n",
       "      <td>0.336742</td>\n",
       "      <td>0.771530</td>\n",
       "      <td>0.698421</td>\n",
       "      <td>-0.092796</td>\n",
       "      <td>0.181799</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>-0.488849</td>\n",
       "      <td>0.114717</td>\n",
       "      <td>0.655202</td>\n",
       "      <td>-0.744915</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.013242</td>\n",
       "      <td>0.052030</td>\n",
       "      <td>0.365005</td>\n",
       "      <td>0.099475</td>\n",
       "      <td>-0.242165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653883</td>\n",
       "      <td>0.261644</td>\n",
       "      <td>-0.046154</td>\n",
       "      <td>0.082290</td>\n",
       "      <td>2.504019</td>\n",
       "      <td>-0.098325</td>\n",
       "      <td>0.797305</td>\n",
       "      <td>-0.070982</td>\n",
       "      <td>0.407613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>-0.745462</td>\n",
       "      <td>0.269164</td>\n",
       "      <td>0.793629</td>\n",
       "      <td>-1.031668</td>\n",
       "      <td>0.535627</td>\n",
       "      <td>-0.082444</td>\n",
       "      <td>0.145839</td>\n",
       "      <td>0.741332</td>\n",
       "      <td>-0.243830</td>\n",
       "      <td>-1.010863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302966</td>\n",
       "      <td>-0.075838</td>\n",
       "      <td>0.623002</td>\n",
       "      <td>-0.057209</td>\n",
       "      <td>-0.034645</td>\n",
       "      <td>0.518699</td>\n",
       "      <td>-0.007314</td>\n",
       "      <td>0.211534</td>\n",
       "      <td>0.712135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>-0.760727</td>\n",
       "      <td>0.404997</td>\n",
       "      <td>0.687271</td>\n",
       "      <td>-1.241401</td>\n",
       "      <td>0.801400</td>\n",
       "      <td>-0.131036</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>0.973352</td>\n",
       "      <td>-0.548477</td>\n",
       "      <td>-1.094265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795708</td>\n",
       "      <td>-0.009668</td>\n",
       "      <td>3.446804</td>\n",
       "      <td>-0.107725</td>\n",
       "      <td>1.102325</td>\n",
       "      <td>-0.099896</td>\n",
       "      <td>1.223172</td>\n",
       "      <td>0.688118</td>\n",
       "      <td>0.733896</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>-0.737530</td>\n",
       "      <td>0.218970</td>\n",
       "      <td>0.868654</td>\n",
       "      <td>-0.936520</td>\n",
       "      <td>0.252549</td>\n",
       "      <td>-0.098225</td>\n",
       "      <td>-0.081343</td>\n",
       "      <td>0.593797</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>-0.550901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019553</td>\n",
       "      <td>0.211147</td>\n",
       "      <td>0.125435</td>\n",
       "      <td>0.096978</td>\n",
       "      <td>-0.080829</td>\n",
       "      <td>-0.077035</td>\n",
       "      <td>0.394715</td>\n",
       "      <td>0.280398</td>\n",
       "      <td>-0.036882</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "4223 -0.618610  0.463183  0.744717 -1.020731  0.811868 -0.058083 -0.183214   \n",
       "1202 -0.488849  0.114717  0.655202 -0.744915  0.074412 -0.013242  0.052030   \n",
       "3262 -0.745462  0.269164  0.793629 -1.031668  0.535627 -0.082444  0.145839   \n",
       "4683 -0.760727  0.404997  0.687271 -1.241401  0.801400 -0.131036 -0.002606   \n",
       "2600 -0.737530  0.218970  0.868654 -0.936520  0.252549 -0.098225 -0.081343   \n",
       "\n",
       "             7         8         9  ...      2039      2040      2041  \\\n",
       "4223  0.905942 -0.576029 -1.222059  ...  0.028469 -0.040667  0.001379   \n",
       "1202  0.365005  0.099475 -0.242165  ...  0.653883  0.261644 -0.046154   \n",
       "3262  0.741332 -0.243830 -1.010863  ...  0.302966 -0.075838  0.623002   \n",
       "4683  0.973352 -0.548477 -1.094265  ...  0.795708 -0.009668  3.446804   \n",
       "2600  0.593797  0.059835 -0.550901  ... -0.019553  0.211147  0.125435   \n",
       "\n",
       "          2042      2043      2044      2045      2046      2047  target  \n",
       "4223 -0.114967  0.336742  0.771530  0.698421 -0.092796  0.181799       2  \n",
       "1202  0.082290  2.504019 -0.098325  0.797305 -0.070982  0.407613       0  \n",
       "3262 -0.057209 -0.034645  0.518699 -0.007314  0.211534  0.712135       2  \n",
       "4683 -0.107725  1.102325 -0.099896  1.223172  0.688118  0.733896       2  \n",
       "2600  0.096978 -0.080829 -0.077035  0.394715  0.280398 -0.036882       2  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(n_base, test_size=0.2, random_state = SEED)\n",
    "print(train.shape, val.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.iloc[:,:-1], train.target\n",
    "X_val, y_val     = val.iloc[:,:-1], val.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanceadomento das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3.5901234567901232, 1: 1.0699043414275202, 2: 0.5596612779060816}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight(class_weight='balanced', classes = np.unique(train.target) ,y = train.target).ravel()\n",
    "class_weights = dict((i,v) for i, v in enumerate(weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state = SEED, class_weight = class_weights)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=0.464 total time=   8.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=0.405 total time=   8.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=0.444 total time=   8.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=0.451 total time=   7.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200;, score=0.460 total time=   7.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=0.472 total time=  19.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=0.411 total time=  21.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=0.435 total time=  20.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=0.435 total time=  20.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=auto, n_estimators=500;, score=0.453 total time=  20.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.464 total time=   8.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.405 total time=   8.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.444 total time=   8.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.451 total time=  20.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.460 total time=  12.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.472 total time=  24.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.411 total time=  20.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.435 total time=  20.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.435 total time=  20.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.453 total time=  20.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.451 total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.412 total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.427 total time=   2.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.431 total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=0.452 total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.455 total time=   5.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.426 total time=   5.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.425 total time=   5.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.436 total time=   5.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=log2, n_estimators=500;, score=0.440 total time=   5.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=0.499 total time=   9.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=0.467 total time=  13.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=0.498 total time=  17.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=0.485 total time=  10.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200;, score=0.486 total time=  24.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=0.509 total time=  24.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=0.467 total time=  24.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=0.501 total time=  24.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=0.464 total time=  24.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, n_estimators=500;, score=0.492 total time=  24.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.499 total time=   9.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.467 total time=   9.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.498 total time=   9.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.485 total time=   9.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.486 total time=   9.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.509 total time=  24.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.467 total time=  24.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.501 total time=  24.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.464 total time=  24.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.492 total time=  24.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.509 total time=   2.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.465 total time=   2.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.471 total time=   2.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.458 total time=   2.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=0.484 total time=   2.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.515 total time=   6.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.473 total time=   6.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.484 total time=   6.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.462 total time=   6.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, n_estimators=500;, score=0.484 total time=   6.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=0.530 total time=  11.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=0.521 total time=  11.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=0.541 total time=  11.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=0.515 total time=  11.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=200;, score=0.519 total time=  11.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=0.549 total time=  28.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=0.530 total time=  28.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=0.552 total time=  28.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=0.505 total time=  28.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, max_features=auto, n_estimators=500;, score=0.522 total time=  28.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.530 total time=  11.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.521 total time=  11.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.541 total time=  11.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.515 total time=  11.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.519 total time=  11.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.549 total time=  29.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.530 total time=  28.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.552 total time=  28.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.505 total time=  28.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.522 total time=  29.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.537 total time=   3.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.501 total time=   3.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.490 total time=   3.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.491 total time=   3.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=0.530 total time=   3.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.543 total time=   7.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.504 total time=   7.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.492 total time=   8.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.486 total time=   7.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, max_features=log2, n_estimators=500;, score=0.526 total time=   7.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=0.558 total time=  13.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=0.529 total time=  13.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=0.554 total time=  13.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=0.524 total time=  16.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=200;, score=0.541 total time=  14.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=0.580 total time=  33.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=0.532 total time=  33.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=0.565 total time=  33.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=0.531 total time=  33.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, max_features=auto, n_estimators=500;, score=0.555 total time=  33.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.558 total time=  13.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.529 total time=  13.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.554 total time=  13.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.524 total time=  13.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.541 total time=  13.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.580 total time=  33.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.532 total time=  32.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.565 total time=  33.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.531 total time=  33.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.555 total time=  33.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.542 total time=   3.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.507 total time=   3.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.548 total time=   3.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.522 total time=   3.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=0.516 total time=   3.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.558 total time=   8.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.532 total time=   8.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.548 total time=   8.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.523 total time=   8.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, max_features=log2, n_estimators=500;, score=0.558 total time=   8.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=0.592 total time=  14.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=0.548 total time=  14.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=0.578 total time=  14.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=0.540 total time=  14.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=200;, score=0.561 total time=  14.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=0.588 total time=  37.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=0.562 total time=  36.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=0.579 total time=  36.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=0.548 total time=  37.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, max_features=auto, n_estimators=500;, score=0.588 total time=  37.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.592 total time=  14.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.548 total time=  14.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.578 total time=  14.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.540 total time=  14.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.561 total time=  14.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.588 total time=  37.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.562 total time=  36.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.579 total time=  36.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.548 total time=  36.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.588 total time=  36.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.553 total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.527 total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.558 total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.541 total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=200;, score=0.578 total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.588 total time=   9.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.556 total time=   9.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.572 total time=   9.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.547 total time=   9.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, max_features=log2, n_estimators=500;, score=0.570 total time=   9.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=0.454 total time=  15.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=0.431 total time=  15.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=0.400 total time=  15.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=0.414 total time=  15.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200;, score=0.431 total time=  15.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=0.460 total time=  38.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=0.427 total time=  38.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=0.416 total time=  39.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=0.428 total time=  38.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=500;, score=0.451 total time=  38.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.454 total time=  15.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.431 total time=  15.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.400 total time=  15.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.414 total time=  15.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=0.431 total time=  15.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.460 total time=  39.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.427 total time=  38.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.416 total time=  38.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.428 total time=  39.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.451 total time=  38.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.463 total time=   4.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.412 total time=   4.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.409 total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.427 total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=0.432 total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.471 total time=  10.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.410 total time=  10.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.430 total time=  10.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.428 total time=  10.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=500;, score=0.445 total time=  10.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=0.490 total time=  19.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=0.464 total time=  19.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=0.500 total time=  19.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=0.453 total time=  19.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200;, score=0.483 total time=  19.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=0.498 total time=  47.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=0.468 total time=  48.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=0.518 total time=  47.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=0.451 total time=  47.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=500;, score=0.481 total time=  48.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.490 total time=  19.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.464 total time=  19.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.500 total time=  19.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.453 total time=  19.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=0.483 total time=  19.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.498 total time=  48.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.468 total time=  47.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.518 total time=  47.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.451 total time=  47.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.481 total time=  48.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.486 total time=   5.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.480 total time=   5.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.476 total time=   5.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.469 total time=   5.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=0.472 total time=   5.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.511 total time=  12.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.465 total time=  12.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.492 total time=  12.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.467 total time=  12.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=500;, score=0.485 total time=  12.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=0.509 total time=  22.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=0.495 total time=  22.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=0.521 total time=  22.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=0.510 total time=  23.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=200;, score=0.523 total time=  22.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=0.546 total time=  56.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=0.523 total time=  56.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=0.546 total time=  56.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=0.517 total time=  56.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, max_features=auto, n_estimators=500;, score=0.532 total time=  56.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.509 total time=  22.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.495 total time=  22.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.521 total time=  22.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.510 total time=  22.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=0.523 total time=  22.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.546 total time=  56.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.523 total time=  55.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.546 total time=  56.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.517 total time=  55.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=500;, score=0.532 total time=  56.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.510 total time=   5.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.515 total time=   5.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.509 total time=   5.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.508 total time=   5.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=0.505 total time=   5.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.546 total time=  14.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.519 total time=  14.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.540 total time=  14.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.495 total time=  14.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, max_features=log2, n_estimators=500;, score=0.532 total time=  14.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=0.559 total time=  25.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=0.545 total time=  26.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=0.557 total time=  25.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=0.525 total time=  25.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=200;, score=0.545 total time=  25.7s\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=0.569 total time= 1.1min\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=0.543 total time= 1.1min\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=0.581 total time= 1.1min\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=0.549 total time= 1.1min\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, max_features=auto, n_estimators=500;, score=0.562 total time= 1.1min\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.559 total time=  25.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.545 total time=  25.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.557 total time=  25.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.525 total time=  25.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=0.545 total time=  25.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.569 total time= 1.1min\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.543 total time= 1.1min\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.581 total time= 1.1min\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.549 total time= 1.2min\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=500;, score=0.562 total time= 1.1min\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.548 total time=   6.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.534 total time=   6.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.547 total time=   6.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.500 total time=   6.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=0.552 total time=   6.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.572 total time=  16.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.545 total time=  16.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.557 total time=  16.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.511 total time=  16.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, max_features=log2, n_estimators=500;, score=0.539 total time=  16.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=0.565 total time=  28.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=0.558 total time=  28.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=0.575 total time=  28.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=0.553 total time=  28.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=200;, score=0.576 total time=  28.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=0.572 total time= 1.2min\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=0.580 total time= 1.2min\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=0.584 total time= 1.2min\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=0.586 total time= 1.2min\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, max_features=auto, n_estimators=500;, score=0.588 total time= 1.2min\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.565 total time=  28.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.558 total time=  28.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.575 total time=  28.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.553 total time=  28.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=200;, score=0.576 total time=  28.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.572 total time= 1.2min\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.580 total time= 1.2min\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.584 total time= 1.2min\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.586 total time= 1.2min\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, max_features=sqrt, n_estimators=500;, score=0.588 total time= 1.2min\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.562 total time=   7.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.548 total time=   7.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.569 total time=   7.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.541 total time=   7.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=200;, score=0.581 total time=   7.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.590 total time=  19.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.567 total time=  19.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.579 total time=  18.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.564 total time=  18.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, max_features=log2, n_estimators=500;, score=0.578 total time=  18.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight={0: 3.5901234567901232,\n",
       "                                                            1: 1.0699043414275202,\n",
       "                                                            2: 0.5596612779060816},\n",
       "                                              random_state=2),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = rfc, param_grid = param_grid, cv = 5, verbose=3)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino - balanced_accuracy :  0.999871696176546\n",
      "Treino - F1 :  0.9995248205319305\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_train)\n",
    "print(\"Treino - balanced_accuracy : \", balanced_accuracy_score(y_train,  y_pred))\n",
    "print(\"Treino - F1 : \", f1_score(y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['negative', 'neutral', 'positive']\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_df = pd.DataFrame(cmn,\n",
    "                     index = labels, \n",
    "                     columns = labels\n",
    "                     )\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.heatmap(cm_df, annot=True ,fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacao - balanced_accuracy :  0.33036934578208105\n",
      "Validacao - F1 :  0.287013251783894\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_val)\n",
    "print(\"Validacao - balanced_accuracy : \", balanced_accuracy_score(y_val,  y_pred))\n",
    "print(\"Validacao - F1 : \", f1_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['negative', 'neutral', 'positive']\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_df = pd.DataFrame(cmn,\n",
    "                     index = labels, \n",
    "                     columns = labels\n",
    "                     )\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.heatmap(cm_df, annot=True ,fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B:\\\\utils\\\\Documentos\\\\MDC\\\\projeto_final\\\\meme-sentiment-analysis/meme-sentiment-analysis/models/saved/models/RF/RandomForest-concatFeatures(roBERTa-Effic).joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid, PATH_TO_MODELS + \"RF/RandomForest-concatFeatures(roBERTa-Effic).joblib\")\n",
    "#rfc = joblib.load(PATH_TO_MODELS + \"RF/RandomForest-concatFeatures(BERT-Effic).joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2487189b5835e73c5fa6cd7f2ed518f6fa1ff6c9bd8da44d17cb8ab10f576c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
